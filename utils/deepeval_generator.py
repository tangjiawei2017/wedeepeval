import os
import sys
import asyncio
import logging
from typing import List, Dict, Optional, Callable
from datetime import datetime

# è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„å¹¶æ·»åŠ  DeepEval æºç è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DEEPEVAL_SOURCE_PATH = os.path.join(PROJECT_ROOT, 'deepeval_source')

if DEEPEVAL_SOURCE_PATH not in sys.path:
    sys.path.insert(0, DEEPEVAL_SOURCE_PATH)
    print(f"ğŸ”§ å·²æ·»åŠ æœ¬åœ° DeepEval æºç è·¯å¾„: {DEEPEVAL_SOURCE_PATH}")

# éªŒè¯å¯¼å…¥è·¯å¾„
try:
    import deepeval
    print(f"âœ… æˆåŠŸå¯¼å…¥ DeepEvalï¼Œè·¯å¾„: {deepeval.__file__}")
    if 'deepeval_source' in deepeval.__file__:
        print("ğŸ¯ ä½¿ç”¨çš„æ˜¯æœ¬åœ° DeepEval æºç ")
    else:
        print("âš ï¸  è­¦å‘Šï¼šä½¿ç”¨çš„æ˜¯ç³»ç»Ÿå®‰è£…çš„ DeepEval åŒ…")
except ImportError as e:
    print(f"âŒ DeepEval å¯¼å…¥å¤±è´¥: {e}")
    raise

# å¯¼å…¥æ‰€éœ€çš„æ¨¡å—
from deepeval.synthesizer import Synthesizer
from deepeval.dataset import EvaluationDataset
from utils.logger import get_logger
from config import API_CONFIG

# è·å–æ—¥å¿—è®°å½•å™¨
logger = get_logger('deepeval_generator', 'business')

class DeepEvalDatasetGenerator:
    """ä½¿ç”¨DeepEvalç”Ÿæˆæ•°æ®é›†çš„å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–DeepEvalæ•°æ®é›†ç”Ÿæˆå™¨"""
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["OPENAI_API_KEY"] = API_CONFIG['openai_api_key']
        os.environ["OPENAI_BASE_URL"] = API_CONFIG['openai_base_url']
        
        # åˆå§‹åŒ–Synthesizerï¼Œä½¿ç”¨æ›´ä¿å®ˆçš„é…ç½®
        self.synthesizer = Synthesizer(
            model=API_CONFIG['openai_model'],
            async_mode=True,
            max_concurrent=1,  # å‡å°‘åˆ°1ä¸ªå¹¶å‘ï¼Œé¿å…è¿‡è½½
            cost_tracking=False
        )
        
        # è®¾ç½®æ¨¡å‹è¶…æ—¶å’Œé‡è¯•å‚æ•°
        if hasattr(self.synthesizer.model, 'timeout'):
            self.synthesizer.model.timeout = 30  # 30ç§’è¶…æ—¶
        if hasattr(self.synthesizer.model, 'max_retries'):
            self.synthesizer.model.max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡
        
        logger.info(f"DeepEvalæ•°æ®é›†ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {API_CONFIG['openai_model']}")
        logger.info(f"APIé…ç½®: {API_CONFIG['openai_base_url']}")
        logger.info(f"å¹¶å‘æ•°: 1, è¶…æ—¶: 30ç§’, é‡è¯•: 2æ¬¡")
    
    async def generate_from_contexts(self, num_questions: int, contexts: List[str], progress_callback=None) -> List[Dict]:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ•°æ®é›†"""
        logger.info(f"å¼€å§‹ä½¿ç”¨DeepEvalåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæ•°æ®é›†: é—®é¢˜æ•°é‡={num_questions}, ä¸Šä¸‹æ–‡æ•°é‡={len(contexts)}")
        
        if progress_callback:
            progress_callback(0, num_questions, "å¼€å§‹å…¨é‡ç”Ÿæˆ...")
        
        try:
            # è®¾ç½®ä¸Šä¸‹æ–‡
            self.synthesizer.contexts = contexts
            
            if progress_callback:
                progress_callback(1, num_questions, "20%")
            
            # ä½¿ç”¨DeepEvalç”Ÿæˆæ•°æ®é›†
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    dataset: EvaluationDataset = await self.synthesizer.a_generate_goldens_from_contexts(
                        num_goldens=num_questions
                    )
                    break
                except Exception as e:
                    logger.error(f"DeepEvalä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    if attempt == max_retries - 1:
                        raise e
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            
            if progress_callback:
                progress_callback(2, num_questions, "40%")
            
            # å¤„ç†ç”Ÿæˆç»“æœ
            qa_items = []
            for item in dataset:
                qa_items.append({
                    'question': item.question,
                    'answer': item.answer,
                    'context': item.context if hasattr(item, 'context') else ""
                })
            
            if progress_callback:
                progress_callback(3, num_questions, "60%")
            
            logger.info(f"DeepEvalä¸Šä¸‹æ–‡ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(qa_items)} ä¸ªä¸­æ–‡é—®ç­”å¯¹")
            
            if progress_callback:
                progress_callback(4, num_questions, "80%")
            
            if progress_callback:
                progress_callback(len(qa_items), num_questions, "100% - ç”Ÿæˆå®Œæˆ")
            
            return qa_items
            
        except Exception as e:
            logger.error(f"ä¸Šä¸‹æ–‡ç”Ÿæˆæ•°æ®é›†å¤±è´¥: {str(e)}")
            raise e

    async def generate_from_documents(self, num_questions: int, documents: List[str], progress_callback=None) -> List[Dict]:
        """åŸºäºæ–‡æ¡£ç”Ÿæˆæ•°æ®é›†"""
        logger.info(f"å¼€å§‹ä½¿ç”¨DeepEvalåŸºäºæ–‡æ¡£ç”Ÿæˆæ•°æ®é›†: é—®é¢˜æ•°é‡={num_questions}, æ–‡æ¡£æ•°é‡={len(documents)}")
        
        if progress_callback:
            progress_callback(0, num_questions, "å¼€å§‹ä»æ–‡æ¡£ç”Ÿæˆ...")
        
        try:
            # è®¾ç½®æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡
            self.synthesizer.contexts = documents
            
            if progress_callback:
                progress_callback(1, num_questions, "20%")
            
            # ä½¿ç”¨DeepEvalç”Ÿæˆæ•°æ®é›†
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    dataset: EvaluationDataset = await self.synthesizer.a_generate_goldens_from_documents(
                        num_goldens=num_questions
                    )
                    break
                except Exception as e:
                    logger.error(f"DeepEvalæ–‡æ¡£ç”Ÿæˆå¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    if attempt == max_retries - 1:
                        raise e
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            
            if progress_callback:
                progress_callback(2, num_questions, "40%")
            
            # å¤„ç†ç”Ÿæˆç»“æœ
            qa_items = []
            for item in dataset:
                qa_items.append({
                    'question': item.question,
                    'answer': item.answer,
                    'context': item.context if hasattr(item, 'context') else ""
                })
            
            if progress_callback:
                progress_callback(3, num_questions, "60%")
            
            logger.info(f"DeepEvalæ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(qa_items)} ä¸ªä¸­æ–‡é—®ç­”å¯¹")
            
            if progress_callback:
                progress_callback(4, num_questions, "80%")
            
            if progress_callback:
                progress_callback(len(qa_items), num_questions, "100% - ç”Ÿæˆå®Œæˆ")
            
            return qa_items
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£ç”Ÿæˆæ•°æ®é›†å¤±è´¥: {str(e)}")
            raise e
    
    async def generate_from_scratch(self, num_questions: int, topic: str, task_description: str, scenario_description: str, progress_callback=None) -> List[Dict]:
        """ä»é›¶å¼€å§‹ç”Ÿæˆæ•°æ®é›†"""
        logger.info(f"å¼€å§‹ä½¿ç”¨DeepEvalä»é›¶ç”Ÿæˆæ•°æ®é›†: é—®é¢˜æ•°é‡={num_questions}, ä¸»é¢˜={topic}, ä»»åŠ¡æè¿°={task_description}, åœºæ™¯æè¿°={scenario_description}")
        
        if progress_callback:
            progress_callback(0, num_questions, "å¼€å§‹ä»é›¶ç”Ÿæˆ...")
        
        try:
            # é…ç½®ç”Ÿæˆå‚æ•°
            self.synthesizer.contexts = [f"ä¸»é¢˜: {topic}\nä»»åŠ¡æè¿°: {task_description}\nåœºæ™¯æè¿°: {scenario_description}"]
            
            if progress_callback:
                progress_callback(1, num_questions, "20%")
            
            # ä½¿ç”¨DeepEvalç”Ÿæˆæ•°æ®é›†
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    dataset: EvaluationDataset = await self.synthesizer.a_generate_goldens_from_scratch(
                        num_goldens=num_questions
                    )
                    break
                except Exception as e:
                    logger.error(f"DeepEvalç”Ÿæˆå¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    if attempt == max_retries - 1:
                        raise e
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            
            if progress_callback:
                progress_callback(2, num_questions, "40%")
            
            # å¤„ç†ç”Ÿæˆç»“æœ
            qa_items = []
            for item in dataset:
                qa_items.append({
                    'question': item.question,
                    'answer': item.answer,
                    'context': item.context if hasattr(item, 'context') else ""
                })
            
            if progress_callback:
                progress_callback(3, num_questions, "60%")
            
            logger.info(f"DeepEvalä»é›¶ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(qa_items)} ä¸ªä¸­æ–‡é—®ç­”å¯¹")
            
            if progress_callback:
                progress_callback(4, num_questions, "80%")
            
            if progress_callback:
                progress_callback(len(qa_items), num_questions, "100% - ç”Ÿæˆå®Œæˆ")
            
            return qa_items
            
        except Exception as e:
            logger.error(f"ä»é›¶ç”Ÿæˆæ•°æ®é›†å¤±è´¥: {str(e)}")
            raise e
    
    async def generate_from_goldens(self, num_questions: int, goldens: List[Dict], progress_callback=None) -> List[Dict]:
        """åŸºäºç°æœ‰é—®ç­”å¯¹æ‰©å†™ç”Ÿæˆæ•°æ®é›†"""
        logger.info(f"å¼€å§‹ä½¿ç”¨DeepEvalæ‰©å†™ç”Ÿæˆæ•°æ®é›†: é—®é¢˜æ•°é‡={num_questions}, ç°æœ‰é—®ç­”å¯¹æ•°é‡={len(goldens)}")
        
        if progress_callback:
            progress_callback(0, num_questions, "å¼€å§‹æ‰©å†™ç”Ÿæˆ...")
        
        try:
            # å‡†å¤‡ç°æœ‰é—®ç­”å¯¹ä½œä¸ºä¸Šä¸‹æ–‡
            contexts = []
            for golden in goldens:
                context = f"é—®é¢˜: {golden.get('question', '')}\nç­”æ¡ˆ: {golden.get('answer', '')}"
                contexts.append(context)
            
            self.synthesizer.contexts = contexts
            
            if progress_callback:
                progress_callback(1, num_questions, "20%")
            
            # ä½¿ç”¨DeepEvalç”Ÿæˆæ•°æ®é›†
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    dataset: EvaluationDataset = await self.synthesizer.a_generate_goldens_from_goldens(
                        num_goldens=num_questions
                    )
                    break
                except Exception as e:
                    logger.error(f"DeepEvalæ‰©å†™ç”Ÿæˆå¤±è´¥ï¼Œå°è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    if attempt == max_retries - 1:
                        raise e
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
            
            if progress_callback:
                progress_callback(2, num_questions, "40%")
            
            # å¤„ç†ç”Ÿæˆç»“æœ
            qa_items = []
            for item in dataset:
                qa_items.append({
                    'question': item.question,
                    'answer': item.answer,
                    'context': item.context if hasattr(item, 'context') else ""
                })
            
            if progress_callback:
                progress_callback(3, num_questions, "60%")
            
            logger.info(f"DeepEvalæ‰©å†™ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(qa_items)} ä¸ªä¸­æ–‡é—®ç­”å¯¹")
            
            if progress_callback:
                progress_callback(4, num_questions, "80%")
            
            if progress_callback:
                progress_callback(len(qa_items), num_questions, "100% - ç”Ÿæˆå®Œæˆ")
            
            return qa_items
            
        except Exception as e:
            logger.error(f"æ‰©å†™ç”Ÿæˆæ•°æ®é›†å¤±è´¥: {str(e)}")
            raise e
    
    def save_dataset(self, qa_items: List[Dict], file_path: str, file_type: str = 'csv'):
        """
        ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶
        
        Args:
            qa_items: é—®ç­”å¯¹åˆ—è¡¨
            file_path: æ–‡ä»¶è·¯å¾„
            file_type: æ–‡ä»¶ç±»å‹ (csv, json, jsonl)
        """
        try:
            # åˆ›å»ºä¸´æ—¶æ•°æ®é›†ç”¨äºä¿å­˜
            temp_dataset = []
            for item in qa_items:
                # ç¡®ä¿ä½¿ç”¨æºç è·¯å¾„å¯¼å…¥
                from deepeval.dataset import Golden
                golden = Golden(
                    input=item['question'],
                    expected_output=item['expected_output']
                )
                temp_dataset.append(golden)
            
            # ä½¿ç”¨DeepEvalçš„ä¿å­˜åŠŸèƒ½
            self.synthesizer.synthetic_goldens = temp_dataset
            saved_path = self.synthesizer.save_as(
                file_type=file_type,
                directory=os.path.dirname(file_path),
                file_name=os.path.basename(file_path).split('.')[0],
                quiet=True
            )
            
            logger.info(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {saved_path}")
            return saved_path
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®é›†å¤±è´¥: {str(e)}")
            raise

# å…¨å±€å®ä¾‹
deepeval_generator = DeepEvalDatasetGenerator() 