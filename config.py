import os
from dotenv import load_dotenv

# æ ¹æ®ç¯å¢ƒå˜é‡åŠ è½½å¯¹åº”çš„é…ç½®æ–‡ä»¶
ENV = os.getenv('ENV', 'development')  # é»˜è®¤å¼€å‘ç¯å¢ƒ
env_file = f'env.{ENV}'

if os.path.exists(env_file):
    load_dotenv(env_file)
    print(f"âœ… åŠ è½½ç¯å¢ƒé…ç½®æ–‡ä»¶: {env_file}")
else:
    print(f"âš ï¸  ç¯å¢ƒé…ç½®æ–‡ä»¶ {env_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

# åŸºç¡€é…ç½®
BASE_CONFIG = {
    'env': ENV,
    'debug': os.getenv('DEBUG', 'false').lower() == 'true',
    'log_level': 'DEBUG' if os.getenv('DEBUG', 'false').lower() == 'true' else 'INFO'
}

# æ•°æ®åº“é…ç½®
DATABASE_CONFIG = {
    'host': os.getenv('DATABASE_HOST', '127.0.0.1'),
    'port': int(os.getenv('DATABASE_PORT', 3306)),
    'database': os.getenv('DATABASE_NAME', 'wedeepeval'),
    'user': os.getenv('DATABASE_USER', 'root'),
    'password': os.getenv('DATABASE_PASSWORD', '123456')
}

# APIé…ç½®
API_CONFIG = {
    'openai_api_key': os.getenv('OPENAI_API_KEY', ''),
    'openai_base_url': os.getenv('OPENAI_BASE_URL', 'https://api.gpt.ge/v1/'),
    'openai_model': os.getenv('OPENAI_MODEL', 'gpt-4-turbo')
}

# æœåŠ¡å™¨é…ç½®
SERVER_CONFIG = {
    'host': os.getenv('SERVER_HOST', '0.0.0.0'),
    'port': int(os.getenv('SERVER_PORT', 8092)),
    'reload': os.getenv('RELOAD', 'false').lower() == 'true'
}

# æ–‡ä»¶é…ç½®
FILE_CONFIG = {
    'output_dir': os.getenv('OUTPUT_DIR', '/tmp'),
    'max_file_size': int(os.getenv('MAX_FILE_SIZE', 10 * 1024 * 1024)),  # 10MB
    'allowed_file_types': ['pdf', 'docx', 'txt', 'csv']
}

# æ—¥å¿—é…ç½®
LOG_CONFIG = {
    'log_dir': os.getenv('LOG_DIR', 'logs'),
    'log_level': os.getenv('LOG_LEVEL', 'INFO'),
    'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    'date_format': '%Y-%m-%d %H:%M:%S',
    'max_bytes': int(os.getenv('LOG_MAX_BYTES', 10 * 1024 * 1024)),  # 10MB
    'backup_count': int(os.getenv('LOG_BACKUP_COUNT', 5)),
    'encoding': 'utf-8'
}

# ç”Ÿæˆå‚æ•°é…ç½®
GENERATION_CONFIG = {
    'batch_size': int(os.getenv('GENERATION_BATCH_SIZE', 3)),  # æ¯æ‰¹ç”Ÿæˆæ•°é‡
    'max_retries': int(os.getenv('GENERATION_MAX_RETRIES', 3)),  # æœ€å¤§é‡è¯•æ¬¡æ•°
    'timeout': int(os.getenv('GENERATION_TIMEOUT', 30)),  # APIè¶…æ—¶æ—¶é—´(ç§’)
    'temperature': float(os.getenv('GENERATION_TEMPERATURE', 0.7)),  # ç”Ÿæˆæ¸©åº¦
    'max_tokens': int(os.getenv('GENERATION_MAX_TOKENS', 2000)),  # æœ€å¤§tokenæ•°
    'single_batch_threshold': int(os.getenv('SINGLE_BATCH_THRESHOLD', 10)),  # å•æ‰¹ç”Ÿæˆé˜ˆå€¼
    'max_single_batch_size': int(os.getenv('MAX_SINGLE_BATCH_SIZE', 15)),  # å•æ‰¹æœ€å¤§ç”Ÿæˆæ•°é‡
}

# æ‰“å°å½“å‰ç¯å¢ƒä¿¡æ¯
print(f"ğŸŒ å½“å‰ç¯å¢ƒ: {ENV}")
print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {BASE_CONFIG['debug']}")
print(f"ğŸ—„ï¸  æ•°æ®åº“: {DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}")
print(f"ğŸŒ æœåŠ¡å™¨: {SERVER_CONFIG['host']}:{SERVER_CONFIG['port']}")
print(f"ğŸ“ æ—¥å¿—ç›®å½•: {LOG_CONFIG['log_dir']}") 