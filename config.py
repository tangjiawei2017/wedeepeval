import os
from dotenv import load_dotenv
import sys
from pathlib import Path

BASE_DIR = Path(__file__).parent.resolve()
# æ ¹æ®ç¯å¢ƒå˜é‡åŠ è½½å¯¹åº”çš„é…ç½®æ–‡ä»¶
ENV = os.getenv('ENV', 'production')  # é»˜è®¤å¼€å‘ç¯å¢ƒ
env_file = BASE_DIR / f'env.{ENV}'

if os.path.exists(env_file):
    load_dotenv(env_file)
    print(f"âœ… åŠ è½½ç¯å¢ƒé…ç½®æ–‡ä»¶: {env_file}")
else:
    print(f"âš ï¸  ç¯å¢ƒé…ç½®æ–‡ä»¶ {env_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

# åŸºç¡€é…ç½®
BASE_CONFIG = {
    'env': ENV,
    'debug': os.getenv('DEBUG', 'false').lower() == 'true',
    'log_level': 'DEBUG' if os.getenv('DEBUG', 'false').lower() == 'true' else 'INFO'
}

# æ•°æ®åº“é…ç½®
DATABASE_CONFIG = {
    'host': os.getenv('DATABASE_HOST', '127.0.0.1'),
    'port': int(os.getenv('DATABASE_PORT', 3306)),
    'database': os.getenv('DATABASE_NAME', 'wedeepeval'),
    'user': os.getenv('DATABASE_USER', 'root'),
    'password': os.getenv('DATABASE_PASSWORD', '123456')
}

# APIé…ç½®
API_CONFIG = {
    'openai_api_key': os.getenv('OPENAI_API_KEY', ''),
    'openai_base_url': os.getenv('OPENAI_BASE_URL', 'https://api.gpt.ge/v1/'),
    'openai_model': os.getenv('OPENAI_MODEL', 'gpt-4-turbo')
}

# Embeddingæ¨¡å‹é…ç½®
EMBEDDING_CONFIG = {
    'embedding_api_key': os.getenv('OPENAI_API_KEY', ''),
    'embedding_base_url': os.getenv('OPENAI_BASE_URL', 'https://api.gpt.ge/v1/'),
    'embedding_model': os.getenv('EMBEDDING_MODEL', 'text-embedding-3-large')
}

# æœåŠ¡å™¨é…ç½®
SERVER_CONFIG = {
    'host': os.getenv('SERVER_HOST', '0.0.0.0'),
    'port': int(os.getenv('SERVER_PORT', 8092)),
    'reload': os.getenv('RELOAD', 'false').lower() == 'true'
}

# æ–‡ä»¶é…ç½®
FILE_CONFIG = {
    'output_dir': os.getenv('OUTPUT_DIR', '/tmp'),
    'max_file_size': int(os.getenv('MAX_FILE_SIZE', 10 * 1024 * 1024)),  # 10MB
    'allowed_file_types': ['pdf', 'docx', 'txt', 'csv']
}

# æ—¥å¿—é…ç½®
LOG_CONFIG = {
    'log_dir': os.getenv('LOG_DIR', 'logs'),
    'log_level': os.getenv('LOG_LEVEL', 'INFO'),
    'log_format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    'date_format': '%Y-%m-%d %H:%M:%S',
    'max_bytes': int(os.getenv('LOG_MAX_BYTES', 10 * 1024 * 1024)),  # 10MB
    'backup_count': int(os.getenv('LOG_BACKUP_COUNT', 5)),
    'encoding': 'utf-8'
}

# ç”Ÿæˆå‚æ•°é…ç½®
GENERATION_CONFIG = {
    'batch_size': int(os.getenv('GENERATION_BATCH_SIZE', 1)),
    'max_retries': int(os.getenv('GENERATION_MAX_RETRIES', 3)),
    'timeout': int(os.getenv('GENERATION_TIMEOUT', 30)),  # 30ç§’
    'temperature': float(os.getenv('GENERATION_TEMPERATURE', 0.7)),
    'max_tokens': int(os.getenv('GENERATION_MAX_TOKENS', 1000)),
    'single_batch_threshold': int(os.getenv('SINGLE_BATCH_THRESHOLD', 5)),
    'max_single_batch_size': int(os.getenv('MAX_SINGLE_BATCH_SIZE', 8))
}

# Previewé…ç½®
PREVIEW_CONFIG = {
    'max_length': int(os.getenv('PREVIEW_MAX_LENGTH', 60)),  # previewå­—æ®µæœ€å¤§é•¿åº¦é™åˆ¶
    'document_items': int(os.getenv('PREVIEW_DOCUMENT_ITEMS', 5)),  # æ–‡æ¡£ç”Ÿæˆpreviewå–å‰å‡ æ¡
    'topic_items': int(os.getenv('PREVIEW_TOPIC_ITEMS', 10)),  # ä¸»é¢˜ç”Ÿæˆpreviewå–å‰å‡ æ¡
    'augment_items': int(os.getenv('PREVIEW_AUGMENT_ITEMS', 5))  # æ‰©å†™ç”Ÿæˆpreviewå–å‰å‡ æ¡
}



# æ‰“å°å½“å‰ç¯å¢ƒä¿¡æ¯
print(f"ğŸŒ å½“å‰ç¯å¢ƒ: {ENV}")
print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {BASE_CONFIG['debug']}")
print(f"ğŸ—„ï¸  æ•°æ®åº“: {DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}")
print(f"ğŸŒ æœåŠ¡å™¨: {SERVER_CONFIG['host']}:{SERVER_CONFIG['port']}")
print(f"OPENAI CONFIG: openai_api_key:{API_CONFIG['openai_api_key']},openai_base_url:{API_CONFIG['openai_base_url']}")
print(f"ğŸ“ æ—¥å¿—ç›®å½•: {LOG_CONFIG['log_dir']}") 